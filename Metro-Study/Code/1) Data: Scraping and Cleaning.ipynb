{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import requests, re, time\n",
    "import pandas_datareader\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "import geopy.distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Impact of Metro-Construction: An Event Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, I seek to find the effect on the price of Copenhagen apartments from the construction of a nearby metro. \n",
    "\n",
    "First, I scrape data of all sold condos in Copenhagen since 1992 using Boliga.dk\n",
    "\n",
    "Second, I use Google's Geocoding-API to convert the found addresses to coordinates. This will help me in step four.\n",
    "\n",
    "Third, I scrape Wikipedia for information on Copenhagen Metro stations.\n",
    "\n",
    "Fourth, I want to find the cloest metro to each apartment, and estimate the distance between the two. This is found to be most easily done by finding coordinates to each apartment and metro, calculate the distance between each apartment and its closest metro and therefrom infer a distance. As the found distance is in the form of a straight line, one must keep in line that the actual walking/cycling distance is longer.\n",
    "\n",
    "Fifth, I must take relevant factors into account in an econometric analysis.\n",
    "\n",
    "This enables me to isolate the effect on the price of a condo from construction of a nearby metro station.\n",
    "\n",
    "The structure of this code-file is the following:\n",
    "\n",
    "1) Scraping Boliga.dk the old-fashioned selenium-way\n",
    "\n",
    "2) Geocoding the found addresses, fetching their coordinates\n",
    "\n",
    "3) Fetching the same data via the API of Boliga.dk (Coordinates are included here, a great bonus)\n",
    "\n",
    "4) Scraping wikipedia for metro stations using selenium\n",
    "\n",
    "5) Finding the closest metro to each apartment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Scraping sales-data from Boliga.dk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define our Connector\n",
    "\n",
    "import requests,os,time\n",
    "def ratelimit(dt):\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(dt) # sleep one second.\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='requests',session=False,path2selenium='',n_tries = 5,timeout=30,waiting_time=0.5):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring. \n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessments\n",
    "    \n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case). \n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    self.waiting_time = waiting_time # define simple rate_limit parameter.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver\n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Firefox(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "    \n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\n",
    "    header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "    if os.path.isfile(logfile):        \n",
    "      if overwrite_log==True:\n",
    "        self.log = open(logfile,'w')\n",
    "        self.log.write(';'.join(header))\n",
    "      else:\n",
    "        self.log = open(logfile,'a')\n",
    "    else:\n",
    "      self.log = open(logfile,'w')\n",
    "      self.log.write(';'.join(header))\n",
    "    ## load log \n",
    "    with open(logfile,'r') as f: # open file\n",
    "        \n",
    "      l = f.read().split('\\n') # read and split file by newlines.\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1][0])+1\n",
    "            \n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, Name used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    "     \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit(self.waiting_time)\n",
    "        t = time.time()\n",
    "        try: # error handling \n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = t - time.time() # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          call_id = self.id # get current unique identifier for the call\n",
    "          self.id+=1 # increment call id\n",
    "          #['id','project_name','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row to be written in the log.\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write log.\n",
    "          self.log.flush()\n",
    "          return response,call_id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt = t - time.time() # define delta t\n",
    "\n",
    "          ## log...\n",
    "          call_id = self.id # define unique identifier\n",
    "          self.id+=1 # increment call_id\n",
    "\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write row to log.\n",
    "          self.log.flush()\n",
    "    else:\n",
    "      t = time.time()\n",
    "      ratelimit(self.waiting_time)\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      ## log\n",
    "      call_id = self.id # define unique identifier for the call. \n",
    "      self.id+=1 # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = t - time.time() # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row \n",
    "      self.log.write('\\n'+';'.join(map(str,row))) # write row to log file.\n",
    "      self.log.flush()\n",
    "    # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "    ## connector.browser.page_source will give you the html.\n",
    "      return None,call_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining aiding functions for later use in the scraper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2gecko = '/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Gecko/geckodriver'\n",
    "\n",
    "def Cookie_Clicker(i): #Accepting cookies:\n",
    "    if i==True:\n",
    "        cookies = connector.browser.find_element_by_xpath('//*[@id=\"coiAccept\"]')\n",
    "        cookies.click()\n",
    "        \n",
    "def Next_Page(i):\n",
    "    if i==True:\n",
    "        next_button = connector.browser.find_element_by_link_text('Næste')\n",
    "        next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the scraping-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = Connector('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Logs/Selenium Scrape.csv',overwrite_log=True,path2selenium=path2gecko,connector_type='selenium')\n",
    "\n",
    "def Scraper(pages,url):\n",
    "    url_base = url\n",
    "    \n",
    "    connector.get(url_base,'Selenium Scrape')\n",
    "    start_time = time.time()\n",
    "\n",
    "    #Waiting for cookies-pop-up:\n",
    "    time.sleep(5)\n",
    "\n",
    "    #Accepting cookies:\n",
    "    Cookie_Clicker(True)\n",
    "\n",
    "    #Wait for load:\n",
    "    time.sleep(3)\n",
    "\n",
    "    #Pull table\n",
    "    df = pd.read_html(connector.browser.page_source)[0]\n",
    "    time.sleep(2)\n",
    "\n",
    "    #Looping over number of wanted pages:\n",
    "    for i in range(0,pages-1): # Minus one as we already scraped the initial page.\n",
    "        if i%100 == 0:\n",
    "            print(f'Page {i} finished')\n",
    "        try:\n",
    "            Next_Page(True)\n",
    "            time.sleep(1)\n",
    "            df_i = pd.read_html(connector.browser.page_source)[0]\n",
    "            df = pd.concat([df,df_i],ignore_index=True)\n",
    "        except:\n",
    "            print('Error')\n",
    "\n",
    "    print(f'Time elapsed: {time.time()-start_time: .2f}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling scraper:\n",
    "\n",
    "I find, that the log-file only logs one entry using this selenium-driven scraper. This is probably due to the fact that the site only loads once, after which the scraper clicks 'Next' and the next table loads, however still on the same request. This is a downside to the manual scraper, as less information on the scraping is harvested. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Page 0 finished\nPage 100 finished\nPage 200 finished\nPage 300 finished\nPage 400 finished\nPage 500 finished\nPage 600 finished\nPage 700 finished\nPage 800 finished\nPage 900 finished\nPage 1000 finished\nPage 1100 finished\nTime elapsed:  1778.02\n"
    }
   ],
   "source": [
    "# Scraping Copenhagen\n",
    "url_broaderCPH = 'https://www.boliga.dk/salg/resultater?propertyType=3&salesDateMin=1992&street=&municipality=101&page=1&sort=date-d'\n",
    "\n",
    "df_broaderCPH = Scraper(1110,url_broaderCPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id          project connector_type             t  delta_t  \\\n0   0  Selenium Scrape       selenium  1.598262e+09 -2.55473   \n\n                                                 url  \\\n0  https://www.boliga.dk/salg/resultater?property...   \n\n                                        redirect_url  response_size  \\\n0  https://www.boliga.dk/salg/resultater?property...         786473   \n\n   response_code  success  error  \n0            NaN      NaN    NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>project</th>\n      <th>connector_type</th>\n      <th>t</th>\n      <th>delta_t</th>\n      <th>url</th>\n      <th>redirect_url</th>\n      <th>response_size</th>\n      <th>response_code</th>\n      <th>success</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>Selenium Scrape</td>\n      <td>selenium</td>\n      <td>1.598262e+09</td>\n      <td>-2.55473</td>\n      <td>https://www.boliga.dk/salg/resultater?property...</td>\n      <td>https://www.boliga.dk/salg/resultater?property...</td>\n      <td>786473</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "log_CPH = pd.read_csv('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Logs/Selenium Scrape.csv',sep=';')\n",
    "log_CPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_broaderCPH.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Scrape broaderCPH raw.pkl')\n",
    "log_CPH.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/log CPH_scrape.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Page 0 finished\nPage 100 finished\nPage 200 finished\nTime elapsed:  390.85\n"
    }
   ],
   "source": [
    "# Scraping Frederiksberg\n",
    "connector = Connector('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Logs/Selenium Scrape.csv',overwrite_log=False,path2selenium=path2gecko,connector_type='selenium')\n",
    "url_FRB = 'https://www.boliga.dk/salg/resultater?propertyType=3&salesDateMin=1992&street=&municipality=147&page=1&sort=date-d'\n",
    "\n",
    "df_FRB = Scraper(247,url_FRB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id          project connector_type             t   delta_t  \\\n0   0  Selenium Scrape       selenium  1.598262e+09 -2.554730   \n1   1  Selenium Scrape       selenium  1.598267e+09 -2.466936   \n\n                                                 url  \\\n0  https://www.boliga.dk/salg/resultater?property...   \n1  https://www.boliga.dk/salg/resultater?property...   \n\n                                        redirect_url  response_size  \\\n0  https://www.boliga.dk/salg/resultater?property...         786473   \n1  https://www.boliga.dk/salg/resultater?property...         787563   \n\n   response_code  success  error  \n0            NaN      NaN    NaN  \n1            NaN      NaN    NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>project</th>\n      <th>connector_type</th>\n      <th>t</th>\n      <th>delta_t</th>\n      <th>url</th>\n      <th>redirect_url</th>\n      <th>response_size</th>\n      <th>response_code</th>\n      <th>success</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>Selenium Scrape</td>\n      <td>selenium</td>\n      <td>1.598262e+09</td>\n      <td>-2.554730</td>\n      <td>https://www.boliga.dk/salg/resultater?property...</td>\n      <td>https://www.boliga.dk/salg/resultater?property...</td>\n      <td>786473</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>Selenium Scrape</td>\n      <td>selenium</td>\n      <td>1.598267e+09</td>\n      <td>-2.466936</td>\n      <td>https://www.boliga.dk/salg/resultater?property...</td>\n      <td>https://www.boliga.dk/salg/resultater?property...</td>\n      <td>787563</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Checking that the second scrape is logged:\n",
    "log_FRB = pd.read_csv('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Logs/Selenium Scrape.csv',sep=';')\n",
    "log_FRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FRB.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Scrape FRB raw.pkl')\n",
    "log_FRB.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/log FRB_scrape.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Total = pd.concat([df_broaderCPH,df_FRB],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total dataframe has 67850 rows.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                Adresse            Købesum  \\\n0  Pakhusvej 6, 1. tv, 2100 København Ø  Købesum 2.700.000   \n1     Ålekistevej 108A, 5, 2720 Vanløse  Købesum 2.400.000   \n2     Kærholmen 19, 1. tv, 2720 Vanløse  Købesum 2.095.000   \n\n              Salgsdato                               Boligtype  \\\n0  Salgsdato 13-08-2020  Boligtype Ejerlejlighed EEjerlejlighed   \n1  Salgsdato 13-08-2020  Boligtype Ejerlejlighed EEjerlejlighed   \n2  Salgsdato 12-08-2020  Boligtype Ejerlejlighed EEjerlejlighed   \n\n          Kr. / m²    Værelser         m²       Byggeår  \\\n0  Kr. / m² 26.471  Værelser 3  m² 102 m²  Byggeår 2007   \n1  Kr. / m² 28.916  Værelser 3   m² 83 m²  Byggeår 1937   \n2  Kr. / m² 36.121  Værelser 2   m² 58 m²  Byggeår 1939   \n\n  Den procentuelle forskel mellem seneste udbudspris og salgsprisen %  \\\n0                                      Prisjustering                    \n1                                  Prisjustering -4%                    \n2                                  Prisjustering -5%                    \n\n                                          Unnamed: 9  \n0  BoligrapporterBoligrapporterFå de bedste argum...  \n1  BoligrapporterBoligrapporterFå de bedste argum...  \n2  BoligrapporterBoligrapporterFå de bedste argum...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adresse</th>\n      <th>Købesum</th>\n      <th>Salgsdato</th>\n      <th>Boligtype</th>\n      <th>Kr. / m²</th>\n      <th>Værelser</th>\n      <th>m²</th>\n      <th>Byggeår</th>\n      <th>Den procentuelle forskel mellem seneste udbudspris og salgsprisen %</th>\n      <th>Unnamed: 9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Pakhusvej 6, 1. tv, 2100 København Ø</td>\n      <td>Købesum 2.700.000</td>\n      <td>Salgsdato 13-08-2020</td>\n      <td>Boligtype Ejerlejlighed EEjerlejlighed</td>\n      <td>Kr. / m² 26.471</td>\n      <td>Værelser 3</td>\n      <td>m² 102 m²</td>\n      <td>Byggeår 2007</td>\n      <td>Prisjustering</td>\n      <td>BoligrapporterBoligrapporterFå de bedste argum...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Ålekistevej 108A, 5, 2720 Vanløse</td>\n      <td>Købesum 2.400.000</td>\n      <td>Salgsdato 13-08-2020</td>\n      <td>Boligtype Ejerlejlighed EEjerlejlighed</td>\n      <td>Kr. / m² 28.916</td>\n      <td>Værelser 3</td>\n      <td>m² 83 m²</td>\n      <td>Byggeår 1937</td>\n      <td>Prisjustering -4%</td>\n      <td>BoligrapporterBoligrapporterFå de bedste argum...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Kærholmen 19, 1. tv, 2720 Vanløse</td>\n      <td>Købesum 2.095.000</td>\n      <td>Salgsdato 12-08-2020</td>\n      <td>Boligtype Ejerlejlighed EEjerlejlighed</td>\n      <td>Kr. / m² 36.121</td>\n      <td>Værelser 2</td>\n      <td>m² 58 m²</td>\n      <td>Byggeår 1939</td>\n      <td>Prisjustering -5%</td>\n      <td>BoligrapporterBoligrapporterFå de bedste argum...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "print(f'Total dataframe has {len(df_Total)} rows.')\n",
    "df_Total.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2) Working with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments = pd.DataFrame()\n",
    "Apartments['Address'] = df_Total['Adresse']\n",
    "\n",
    "# Translating to english and datetime\n",
    "dates = [i[10:] for i in df_Total['Salgsdato']]\n",
    "Apartments['Date_sold'] = [datetime.datetime(year=int(i[6:]),month=int(i[3:5]),day=int(i[:2]),)\n",
    "    for i in dates\n",
    "]\n",
    "\n",
    "Apartments['Price'] = [int(i[8:].replace('.',''))\n",
    "    for i in df_Total['Købesum']\n",
    "]\n",
    "\n",
    "Apartments['Price_sq_m'] = [int(i[9:].replace('.',''))\n",
    "    for i in df_Total['Kr. / m²']\n",
    "]\n",
    "\n",
    "Apartments['Rooms'] = [int(i[9:])\n",
    "    for i in df_Total['Værelser']\n",
    "]\n",
    "\n",
    "Apartments.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                Address  Date_sold    Price  Price_sq_m  Rooms\n0  Pakhusvej 6, 1. tv, 2100 København Ø 2020-08-13  2700000       26471      3\n1     Ålekistevej 108A, 5, 2720 Vanløse 2020-08-13  2400000       28916      3\n2     Kærholmen 19, 1. tv, 2720 Vanløse 2020-08-12  2095000       36121      2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Address</th>\n      <th>Date_sold</th>\n      <th>Price</th>\n      <th>Price_sq_m</th>\n      <th>Rooms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Pakhusvej 6, 1. tv, 2100 København Ø</td>\n      <td>2020-08-13</td>\n      <td>2700000</td>\n      <td>26471</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Ålekistevej 108A, 5, 2720 Vanløse</td>\n      <td>2020-08-13</td>\n      <td>2400000</td>\n      <td>28916</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Kærholmen 19, 1. tv, 2720 Vanløse</td>\n      <td>2020-08-12</td>\n      <td>2095000</td>\n      <td>36121</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "Apartments = pickle.load(open('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 1.pkl','rb'))\n",
    "Apartments.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new column is added, using RegEx to remove all text between the commas. This substring expresses which door in the given apartment complex the address belongs to, and is thus irrelevant for the distance to nearest Metro. This is due to a later issue with the API not being able to recognize the address otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                Address  Date_sold    Price  Price_sq_m  \\\n0  Pakhusvej 6, 1. tv, 2100 København Ø 2020-08-13  2700000       26471   \n1     Ålekistevej 108A, 5, 2720 Vanløse 2020-08-13  2400000       28916   \n2     Kærholmen 19, 1. tv, 2720 Vanløse 2020-08-12  2095000       36121   \n\n   Rooms            Address transformed  \n0      3   Pakhusvej 6 2100 København Ø  \n1      3  Ålekistevej 108A 2720 Vanløse  \n2      2      Kærholmen 19 2720 Vanløse  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Address</th>\n      <th>Date_sold</th>\n      <th>Price</th>\n      <th>Price_sq_m</th>\n      <th>Rooms</th>\n      <th>Address transformed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Pakhusvej 6, 1. tv, 2100 København Ø</td>\n      <td>2020-08-13</td>\n      <td>2700000</td>\n      <td>26471</td>\n      <td>3</td>\n      <td>Pakhusvej 6 2100 København Ø</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Ålekistevej 108A, 5, 2720 Vanløse</td>\n      <td>2020-08-13</td>\n      <td>2400000</td>\n      <td>28916</td>\n      <td>3</td>\n      <td>Ålekistevej 108A 2720 Vanløse</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Kærholmen 19, 1. tv, 2720 Vanløse</td>\n      <td>2020-08-12</td>\n      <td>2095000</td>\n      <td>36121</td>\n      <td>2</td>\n      <td>Kærholmen 19 2720 Vanløse</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "Apartments['Address transformed'] = [re.sub(',[^>]+,', '',i)\n",
    "for i in Apartments['Address']\n",
    "    ]\n",
    "Apartments.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting data by address and date sold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sorted = Apartments.sort_values(['Address','Date_sold'])\n",
    "\n",
    "# Problem with some pgaes being scraped more than once - deleting duplicate rows:\n",
    "data_sorted.drop_duplicates(inplace=True)\n",
    "data_sorted = data_sorted.sort_values(['Date_sold'])\n",
    "data_sorted['Price_mio'] = data_sorted['Price']/10**6\n",
    "data_sorted['Price_sq_m_1000'] = data_sorted['Price_sq_m']/10**3\n",
    "data_sorted = data_sorted.reset_index()\n",
    "\n",
    "# Sorting and creating daily averages and moving average for graphing:\n",
    "dailyavg = data_sorted.groupby('Date_sold').agg(\n",
    "    Dailyavg_mio = ('Price_mio','mean'),\n",
    "    Dailyavg_sq = ('Price_sq_m_1000','mean')\n",
    ")\n",
    "dailyavg['Day'] = dailyavg.index.to_list()\n",
    "dailyavg['MovAvg'] = dailyavg['Dailyavg_sq'].rolling(window=500,center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   level_0  index                                            Address  \\\n0        0  67849  Sankt Thomas Alle 11, 4. th, 1824 Frederiksberg C   \n1        1  67848          Moltkesvej 61, st. th, 2000 Frederiksberg   \n2        2  67847  Frederiksberg Alle 34, 1. th, 1820 Frederiksbe...   \n\n   Date_sold    Price  Price_sq_m  Rooms  \\\n0 1992-01-24   725800        6598      4   \n1 1992-01-26   690000        7841      4   \n2 1992-02-02  1250000        6188      6   \n\n                          Address transformed  Price_mio  Price_sq_m_1000  \n0   Sankt Thomas Alle 11 1824 Frederiksberg C     0.7258            6.598  \n1            Moltkesvej 61 2000 Frederiksberg     0.6900            7.841  \n2  Frederiksberg Alle 34 1820 Frederiksberg C     1.2500            6.188  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>Address</th>\n      <th>Date_sold</th>\n      <th>Price</th>\n      <th>Price_sq_m</th>\n      <th>Rooms</th>\n      <th>Address transformed</th>\n      <th>Price_mio</th>\n      <th>Price_sq_m_1000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>67849</td>\n      <td>Sankt Thomas Alle 11, 4. th, 1824 Frederiksberg C</td>\n      <td>1992-01-24</td>\n      <td>725800</td>\n      <td>6598</td>\n      <td>4</td>\n      <td>Sankt Thomas Alle 11 1824 Frederiksberg C</td>\n      <td>0.7258</td>\n      <td>6.598</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>67848</td>\n      <td>Moltkesvej 61, st. th, 2000 Frederiksberg</td>\n      <td>1992-01-26</td>\n      <td>690000</td>\n      <td>7841</td>\n      <td>4</td>\n      <td>Moltkesvej 61 2000 Frederiksberg</td>\n      <td>0.6900</td>\n      <td>7.841</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>67847</td>\n      <td>Frederiksberg Alle 34, 1. th, 1820 Frederiksbe...</td>\n      <td>1992-02-02</td>\n      <td>1250000</td>\n      <td>6188</td>\n      <td>6</td>\n      <td>Frederiksberg Alle 34 1820 Frederiksberg C</td>\n      <td>1.2500</td>\n      <td>6.188</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# The apartment data now looks like this:\n",
    "Apartments = data_sorted\n",
    "Apartments.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Dailyavg_mio  Dailyavg_sq        Day  MovAvg\nDate_sold                                               \n1992-01-24        0.7258        6.598 1992-01-24     NaN\n1992-01-26        0.6900        7.841 1992-01-26     NaN\n1992-02-02        1.2500        6.188 1992-02-02     NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dailyavg_mio</th>\n      <th>Dailyavg_sq</th>\n      <th>Day</th>\n      <th>MovAvg</th>\n    </tr>\n    <tr>\n      <th>Date_sold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1992-01-24</td>\n      <td>0.7258</td>\n      <td>6.598</td>\n      <td>1992-01-24</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1992-01-26</td>\n      <td>0.6900</td>\n      <td>7.841</td>\n      <td>1992-01-26</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1992-02-02</td>\n      <td>1.2500</td>\n      <td>6.188</td>\n      <td>1992-02-02</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# The grouped mean- and moving average-data looks like this (MovAvg has NaN-values in beginning and ending of series):\n",
    "dailyavg.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the apartments by sub-areas within Copenhagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferring the area from the last part of the address:\n",
    "Apartments['Area'] = 'NaN'\n",
    "for i in range(0,len(Apartments)):\n",
    "    if Apartments['Address'][i][-1] == 'N':\n",
    "        Apartments['Area'][i] = 'N'\n",
    "        # Solving issue with differentiating between NV and V:\n",
    "    elif Apartments['Address'][i][-2:] == 'NV':\n",
    "        if Apartments['Address'][i][-2] == ' V':\n",
    "            Apartments['Area'][i] = 'V'\n",
    "        else: \n",
    "            Apartments['Area'][i] = 'NV'\n",
    "    elif Apartments['Address'][i][-1] == 'Ø':\n",
    "        Apartments['Area'][i] = 'Ø'\n",
    "    elif Apartments['Address'][i][-1] == 'K':\n",
    "        Apartments['Area'][i] = 'K'\n",
    "    elif Apartments['Address'][i][-1] == 'S':\n",
    "        Apartments['Area'][i] = 'S'\n",
    "    elif Apartments['Address'][i][-5:] == 'Valby':\n",
    "        Apartments['Area'][i] = 'Valby'\n",
    "    elif Apartments['Address'][i][-13:] == 'Frederiksberg':\n",
    "        Apartments['Area'][i] = 'FRB'\n",
    "    elif Apartments['Address'][i][-1:] == 'C':\n",
    "        Apartments['Area'][i] = 'FRB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 2.pkl')\n",
    "Apartments = pickle.load(open('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 2.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   level_0  index                                            Address  \\\n0        0  67849  Sankt Thomas Alle 11, 4. th, 1824 Frederiksberg C   \n1        1  67848          Moltkesvej 61, st. th, 2000 Frederiksberg   \n2        2  67847  Frederiksberg Alle 34, 1. th, 1820 Frederiksbe...   \n\n   Date_sold    Price  Price_sq_m  Rooms  \\\n0 1992-01-24   725800        6598      4   \n1 1992-01-26   690000        7841      4   \n2 1992-02-02  1250000        6188      6   \n\n                          Address transformed  Price_mio  Price_sq_m_1000 Area  \n0   Sankt Thomas Alle 11 1824 Frederiksberg C     0.7258            6.598  FRB  \n1            Moltkesvej 61 2000 Frederiksberg     0.6900            7.841  FRB  \n2  Frederiksberg Alle 34 1820 Frederiksberg C     1.2500            6.188  FRB  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>Address</th>\n      <th>Date_sold</th>\n      <th>Price</th>\n      <th>Price_sq_m</th>\n      <th>Rooms</th>\n      <th>Address transformed</th>\n      <th>Price_mio</th>\n      <th>Price_sq_m_1000</th>\n      <th>Area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>67849</td>\n      <td>Sankt Thomas Alle 11, 4. th, 1824 Frederiksberg C</td>\n      <td>1992-01-24</td>\n      <td>725800</td>\n      <td>6598</td>\n      <td>4</td>\n      <td>Sankt Thomas Alle 11 1824 Frederiksberg C</td>\n      <td>0.7258</td>\n      <td>6.598</td>\n      <td>FRB</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>67848</td>\n      <td>Moltkesvej 61, st. th, 2000 Frederiksberg</td>\n      <td>1992-01-26</td>\n      <td>690000</td>\n      <td>7841</td>\n      <td>4</td>\n      <td>Moltkesvej 61 2000 Frederiksberg</td>\n      <td>0.6900</td>\n      <td>7.841</td>\n      <td>FRB</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>67847</td>\n      <td>Frederiksberg Alle 34, 1. th, 1820 Frederiksbe...</td>\n      <td>1992-02-02</td>\n      <td>1250000</td>\n      <td>6188</td>\n      <td>6</td>\n      <td>Frederiksberg Alle 34 1820 Frederiksberg C</td>\n      <td>1.2500</td>\n      <td>6.188</td>\n      <td>FRB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "Apartments.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Geocoding: Address to coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Defining the Geocoding-function, finding coordinates from a given address:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function which returns the coordinates for a given address, using the Google Geocode API. I am using a free voucher of DKK 2,000. I need to pull coordinates for around 55 thousand adresses, this will spend around DKK 1,800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "def Geocode_Google(address):\n",
    "    spec_params = {'key' : #REMOVED\n",
    "          'address' : address,\n",
    "    }\n",
    "    d = requests.get(geo_url, params=spec_params)\n",
    "    json_data = d.json()\n",
    "    subdata = json_data['results']\n",
    "    return (subdata[0]['geometry']['location']['lat'],subdata[0]['geometry']['location']['lng'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Finding Coordinates to each apartment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I use the Geocode-function to pull coordinates for all apartments in the dataset. This process took around 8 hours, so I split it up into stages, saving to pickle for each pull in intervals of 5000 pulls, after which I concatenate to a single dataframe and add this column to the original dataset for each apartment. Below, this process has been simplified for easier readability. The stage-pickles are saved in the /Pickles-folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments['Coordinates'] = [Geocode_Google(i) for i in Apartments['Address transformed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments = pickle.load(open('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 3.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                Address            Address transformed   Area  \\\n0  Stengade 52B, 1. 1, 2200 København N  Stengade 52B 2200 København N      N   \n1     Bryggerivej 10, 1. th, 2500 Valby      Bryggerivej 10 2500 Valby  Valby   \n2  Solvænget 5, 3. tv, 2100 København Ø   Solvænget 5 2100 København Ø      Ø   \n\n              Coordinates  Date_sold    Price  Price_mio  Price_sq_m_1000  \\\n0  (55.687083, 12.554688) 1994-02-11   300710   0.300710            5.896   \n1  (55.660475, 12.518974) 1994-02-11   344101   0.344101            5.550   \n2   (55.719198, 12.57804) 1994-02-11  1090300   1.090300            7.788   \n\n   Rooms  \n0      1  \n1      2  \n2      4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Address</th>\n      <th>Address transformed</th>\n      <th>Area</th>\n      <th>Coordinates</th>\n      <th>Date_sold</th>\n      <th>Price</th>\n      <th>Price_mio</th>\n      <th>Price_sq_m_1000</th>\n      <th>Rooms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Stengade 52B, 1. 1, 2200 København N</td>\n      <td>Stengade 52B 2200 København N</td>\n      <td>N</td>\n      <td>(55.687083, 12.554688)</td>\n      <td>1994-02-11</td>\n      <td>300710</td>\n      <td>0.300710</td>\n      <td>5.896</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Bryggerivej 10, 1. th, 2500 Valby</td>\n      <td>Bryggerivej 10 2500 Valby</td>\n      <td>Valby</td>\n      <td>(55.660475, 12.518974)</td>\n      <td>1994-02-11</td>\n      <td>344101</td>\n      <td>0.344101</td>\n      <td>5.550</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Solvænget 5, 3. tv, 2100 København Ø</td>\n      <td>Solvænget 5 2100 København Ø</td>\n      <td>Ø</td>\n      <td>(55.719198, 12.57804)</td>\n      <td>1994-02-11</td>\n      <td>1090300</td>\n      <td>1.090300</td>\n      <td>7.788</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "Apartments.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above is a cleaned dataframe of the basic information on all the scraped apartments - before the closest metro is found. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Using Boliga.dk's API\n",
    "\n",
    "Using the same connector as defined above, I now call the API of the page via requests instead and see, what kind of apartment-data I get this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = Connector('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Logs/API Scrape.csv',overwrite_log=True,path2selenium=path2gecko,connector_type='requests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.boliga.dk/api/v2/sold/search/results?propertyType=3&municipality=101&salesDateMin=1992&salesDateMax=today&sort=date-d&page=1&street='\n",
    "\n",
    "# Testing, calling the API once to see what kind of data it spits out.\n",
    "r, _ = connector.get(url, 'API Scrape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['meta', 'results'])"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "data = r.json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'pageIndex': 1,\n 'pageSize': 50,\n 'totalCount': 55547,\n 'totalPages': 1111,\n 'minPage': 1,\n 'maxPage': 6,\n 'countFrom': 1,\n 'countTo': 50}"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "data['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['estateId', 'address', 'zipCode', 'price', 'soldDate', 'propertyType', 'saleType', 'sqmPrice', 'rooms', 'size', 'buildYear', 'change', 'guid', 'latitude', 'longitude', 'municipalityCode', 'estateCode', 'city', 'groupKey', 'canGetVR'])"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "data['results'][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the API-fetcher\n",
    "\n",
    "def API(pages,municipality):\n",
    "    Apartmentlist = [] \n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(1,pages+1):\n",
    "        if i % 50 == 0:\n",
    "            print(f'Iteration: {i}')\n",
    "        url = f'https://api.boliga.dk/api/v2/sold/search/results?propertyType=3&municipality={municipality}&salesDateMin=1992&salesDateMax=today&sort=date-d&page={i}&street='\n",
    "\n",
    "        try: \n",
    "            r, _ = connector.get(url, 'Boliga Scrape')\n",
    "            Apartmentlist.append(r.json())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "    time.sleep(0.2)\n",
    "    print(f'Time elapsed: {time.time()-start_time: .2f}')\n",
    "    return Apartmentlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration: 50\nIteration: 100\nIteration: 150\nIteration: 200\nIteration: 250\nIteration: 300\nIteration: 350\nIteration: 400\nIteration: 450\nIteration: 500\nIteration: 550\nIteration: 600\nIteration: 650\nIteration: 700\nIteration: 750\nIteration: 800\nIteration: 850\nIteration: 900\nIteration: 950\nIteration: 1000\nIteration: 1050\nIteration: 1100\nTime elapsed:  997.69\n"
    }
   ],
   "source": [
    "CPH_Apartments = API(1110,101) # Copenhagen: Municipality 101\n",
    "CPH_Apartments_df = pd.concat([pd.DataFrame(data['results']) for data in CPH_Apartments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration: 50\nIteration: 100\nIteration: 150\nIteration: 200\nTime elapsed:  186.98\n"
    }
   ],
   "source": [
    "FRB_Apartments = API(247,147) # Copenhagen: Municipality 147\n",
    "FRB_Apartments_df = pd.concat([pd.DataFrame(data['results']) for data in FRB_Apartments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total dataframe has 67850 rows.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   estateId              address  zipCode    price                  soldDate  \\\n0         0   Pakhusvej 6, 1. tv     2100  2700000  2020-08-12T22:00:00.000Z   \n1   1661795  Ålekistevej 108A, 5     2720  2400000  2020-08-12T22:00:00.000Z   \n2   1673486  Kærholmen 19, 1. tv     2720  2095000  2020-08-11T22:00:00.000Z   \n\n   propertyType   saleType   sqmPrice  rooms  size  buildYear    change  \\\n0             3  Fam. Salg  26470.588    3.0   102       2007  0.000000   \n1             3  Alm. Salg  28915.662    3.0    83       1937 -3.807615   \n2             3  Alm. Salg  36120.690    2.0    58       1939 -4.555809   \n\n                                   guid   latitude  longitude  \\\n0  C4966E13-7583-40A3-9DCD-541E9076B1B7  55.697025  12.593633   \n1  5B608A1D-B940-471B-BA16-9695E80CB649  55.685596  12.483170   \n2  E85F5579-CD0F-4D88-90FF-FCCA3E146FCC  55.681316  12.489333   \n\n   municipalityCode  estateCode         city groupKey  canGetVR  \n0               101        4365  København Ø     None      True  \n1               101      684776      Vanløse     None      True  \n2               101      849511      Vanløse     None      True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>estateId</th>\n      <th>address</th>\n      <th>zipCode</th>\n      <th>price</th>\n      <th>soldDate</th>\n      <th>propertyType</th>\n      <th>saleType</th>\n      <th>sqmPrice</th>\n      <th>rooms</th>\n      <th>size</th>\n      <th>buildYear</th>\n      <th>change</th>\n      <th>guid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>municipalityCode</th>\n      <th>estateCode</th>\n      <th>city</th>\n      <th>groupKey</th>\n      <th>canGetVR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>Pakhusvej 6, 1. tv</td>\n      <td>2100</td>\n      <td>2700000</td>\n      <td>2020-08-12T22:00:00.000Z</td>\n      <td>3</td>\n      <td>Fam. Salg</td>\n      <td>26470.588</td>\n      <td>3.0</td>\n      <td>102</td>\n      <td>2007</td>\n      <td>0.000000</td>\n      <td>C4966E13-7583-40A3-9DCD-541E9076B1B7</td>\n      <td>55.697025</td>\n      <td>12.593633</td>\n      <td>101</td>\n      <td>4365</td>\n      <td>København Ø</td>\n      <td>None</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1661795</td>\n      <td>Ålekistevej 108A, 5</td>\n      <td>2720</td>\n      <td>2400000</td>\n      <td>2020-08-12T22:00:00.000Z</td>\n      <td>3</td>\n      <td>Alm. Salg</td>\n      <td>28915.662</td>\n      <td>3.0</td>\n      <td>83</td>\n      <td>1937</td>\n      <td>-3.807615</td>\n      <td>5B608A1D-B940-471B-BA16-9695E80CB649</td>\n      <td>55.685596</td>\n      <td>12.483170</td>\n      <td>101</td>\n      <td>684776</td>\n      <td>Vanløse</td>\n      <td>None</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1673486</td>\n      <td>Kærholmen 19, 1. tv</td>\n      <td>2720</td>\n      <td>2095000</td>\n      <td>2020-08-11T22:00:00.000Z</td>\n      <td>3</td>\n      <td>Alm. Salg</td>\n      <td>36120.690</td>\n      <td>2.0</td>\n      <td>58</td>\n      <td>1939</td>\n      <td>-4.555809</td>\n      <td>E85F5579-CD0F-4D88-90FF-FCCA3E146FCC</td>\n      <td>55.681316</td>\n      <td>12.489333</td>\n      <td>101</td>\n      <td>849511</td>\n      <td>Vanløse</td>\n      <td>None</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "Apartments_API = pd.concat([CPH_Apartments_df,FRB_Apartments_df],ignore_index=True)\n",
    "Apartments_API.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data API RAW.pkl')\n",
    "print(f'Total dataframe has {len(Apartments_API)} rows.')\n",
    "Apartments_API.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Working with the data\n",
    "I streamline the data, so it has the same characteristics as the information fetched by the manual scraper. This allows the rest of the code to work on both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments_API.rename(columns={'address':'Address','price':'Price','sqmPrice':'Price_sq_m','rooms':'Rooms','size':'sq_m'},inplace=True)\n",
    "\n",
    "Apartments_API['Address'] = Apartments_API['Address'] + ', ' + Apartments_API['city'] #Including area and city in address, so it resembles the scraper.\n",
    "Apartments_API['Address transformed'] = [re.sub(',[^>]+,', '',i)\n",
    "for i in Apartments_API['Address']\n",
    "    ]\n",
    "\n",
    "Apartments_API['Price_mio'] = Apartments_API['Price']/10**6\n",
    "Apartments_API['Price_sq_m_1000'] = Apartments_API['Price_sq_m']/10**3\n",
    "\n",
    "# Date sold\n",
    "dates = [i[:10] for i in Apartments_API['soldDate']]\n",
    "Apartments_API['Date_sold'] = [datetime.datetime(year=int(i[:4]),month=int(i[5:7]),day=int(i[8:]),)\n",
    "    for i in dates\n",
    "]\n",
    "\n",
    "Apartments_API['Coordinates'] = [(Apartments_API['latitude'][i],Apartments_API['longitude'][i]) for i in range(0,len(Apartments_API))]\n",
    "\n",
    "Apartments_API['Rooms'] = [int(i) for i in Apartments_API['Rooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferring the area from the last part of the address:\n",
    "Apartments_API['Area'] = 'NaN'\n",
    "for i in range(0,len(Apartments_API)):\n",
    "    if Apartments_API['city'][i][-1] == 'N':\n",
    "        Apartments_API['Area'][i] = 'N'\n",
    "        # Solving issue with differentiating between NV and V:\n",
    "    elif Apartments_API['city'][i][-2:] == 'NV':\n",
    "        if Apartments_API['city'][i][-2] == ' V':\n",
    "            Apartments_API['Area'][i] = 'V'\n",
    "        else: \n",
    "            Apartments_API['Area'][i] = 'NV'\n",
    "    elif Apartments_API['city'][i][-1] == 'Ø':\n",
    "        Apartments_API['Area'][i] = 'Ø'\n",
    "    elif Apartments_API['city'][i][-1] == 'K':\n",
    "        Apartments_API['Area'][i] = 'K'\n",
    "    elif Apartments_API['city'][i][-1] == 'S':\n",
    "        Apartments_API['Area'][i] = 'S'\n",
    "    elif Apartments_API['city'][i][-5:] == 'Valby':\n",
    "        Apartments_API['Area'][i] = 'Valby'\n",
    "    elif Apartments_API['city'][i][-13:] == 'Frederiksberg':\n",
    "        Apartments_API['Area'][i] = 'FRB'\n",
    "    elif Apartments_API['city'][i][-1:] == 'C':\n",
    "        Apartments_API['Area'][i] = 'FRB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments_API.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data API RAW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments_API = pd.read_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data API RAW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total dataframe has 67850 rows.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   estateId                          Address  zipCode    Price  \\\n0         0  Pakhusvej 6, 1. tv, København Ø     2100  2700000   \n1   1661795     Ålekistevej 108A, 5, Vanløse     2720  2400000   \n2   1673486     Kærholmen 19, 1. tv, Vanløse     2720  2095000   \n\n                   soldDate  propertyType   saleType  Price_sq_m  Rooms  sq_m  \\\n0  2020-08-12T22:00:00.000Z             3  Fam. Salg   26470.588      3   102   \n1  2020-08-12T22:00:00.000Z             3  Alm. Salg   28915.662      3    83   \n2  2020-08-11T22:00:00.000Z             3  Alm. Salg   36120.690      2    58   \n\n   ...  estateCode         city groupKey  canGetVR       Address transformed  \\\n0  ...        4365  København Ø     None      True   Pakhusvej 6 København Ø   \n1  ...      684776      Vanløse     None      True  Ålekistevej 108A Vanløse   \n2  ...      849511      Vanløse     None      True      Kærholmen 19 Vanløse   \n\n   Price_mio  Price_sq_m_1000  Date_sold             Coordinates  Area  \n0      2.700        26.470588 2020-08-12  (55.697025, 12.593633)     Ø  \n1      2.400        28.915662 2020-08-12   (55.685596, 12.48317)   NaN  \n2      2.095        36.120690 2020-08-11  (55.681316, 12.489333)   NaN  \n\n[3 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>estateId</th>\n      <th>Address</th>\n      <th>zipCode</th>\n      <th>Price</th>\n      <th>soldDate</th>\n      <th>propertyType</th>\n      <th>saleType</th>\n      <th>Price_sq_m</th>\n      <th>Rooms</th>\n      <th>sq_m</th>\n      <th>...</th>\n      <th>estateCode</th>\n      <th>city</th>\n      <th>groupKey</th>\n      <th>canGetVR</th>\n      <th>Address transformed</th>\n      <th>Price_mio</th>\n      <th>Price_sq_m_1000</th>\n      <th>Date_sold</th>\n      <th>Coordinates</th>\n      <th>Area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>Pakhusvej 6, 1. tv, København Ø</td>\n      <td>2100</td>\n      <td>2700000</td>\n      <td>2020-08-12T22:00:00.000Z</td>\n      <td>3</td>\n      <td>Fam. Salg</td>\n      <td>26470.588</td>\n      <td>3</td>\n      <td>102</td>\n      <td>...</td>\n      <td>4365</td>\n      <td>København Ø</td>\n      <td>None</td>\n      <td>True</td>\n      <td>Pakhusvej 6 København Ø</td>\n      <td>2.700</td>\n      <td>26.470588</td>\n      <td>2020-08-12</td>\n      <td>(55.697025, 12.593633)</td>\n      <td>Ø</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1661795</td>\n      <td>Ålekistevej 108A, 5, Vanløse</td>\n      <td>2720</td>\n      <td>2400000</td>\n      <td>2020-08-12T22:00:00.000Z</td>\n      <td>3</td>\n      <td>Alm. Salg</td>\n      <td>28915.662</td>\n      <td>3</td>\n      <td>83</td>\n      <td>...</td>\n      <td>684776</td>\n      <td>Vanløse</td>\n      <td>None</td>\n      <td>True</td>\n      <td>Ålekistevej 108A Vanløse</td>\n      <td>2.400</td>\n      <td>28.915662</td>\n      <td>2020-08-12</td>\n      <td>(55.685596, 12.48317)</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1673486</td>\n      <td>Kærholmen 19, 1. tv, Vanløse</td>\n      <td>2720</td>\n      <td>2095000</td>\n      <td>2020-08-11T22:00:00.000Z</td>\n      <td>3</td>\n      <td>Alm. Salg</td>\n      <td>36120.690</td>\n      <td>2</td>\n      <td>58</td>\n      <td>...</td>\n      <td>849511</td>\n      <td>Vanløse</td>\n      <td>None</td>\n      <td>True</td>\n      <td>Kærholmen 19 Vanløse</td>\n      <td>2.095</td>\n      <td>36.120690</td>\n      <td>2020-08-11</td>\n      <td>(55.681316, 12.489333)</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "print(f'Total dataframe has {len(Apartments_API)} rows.')\n",
    "Apartments_API.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Scraping Metro-Data\n",
    "\n",
    "By scraping danish Wikipedia-sites for Metro stations in Copenhagen, I can find Address, year built and other relevant information.\n",
    "\n",
    "One problem is, that the information-tables on Wikipedia-pages do not contain the same number of rows and thus amount of information. This is resolved by creating a list of dictionaries, in which each element is a dictionary involving all information from a given table.\n",
    "Selected information is drawn from here and appended to a finished DataFrame, containing all relevant Metro-information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = Connector('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Logs/MetroLog.csv',overwrite_log=True,path2selenium='/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Gecko/geckodriver',connector_type='selenium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Scraper-function:\n",
    "def WikiScraper(no_metros):\n",
    "    url = 'https://da.wikipedia.org/wiki/Stationer_p%C3%A5_K%C3%B8benhavns_Metro'\n",
    "    response,call_id = connector.get(url,'Metroer')\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Creating DataFrame and dictionary for information-storing:\n",
    "    data = pd.DataFrame()\n",
    "    dic_list = []\n",
    "\n",
    "\n",
    "    for i in range(1,no_metros+1):\n",
    "        link = connector.browser.find_element_by_xpath(f'/html/body/div[3]/div[3]/div[5]/div/table[1]/tbody/tr[{i}]/td[1]/a')\n",
    "        link.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # READ INFORMATION\n",
    "        # 1.1) Appending all information to DataFrame\n",
    "        table = pd.read_html(connector.browser.page_source)[0]\n",
    "        data[f'Traits_{i}'] = table.iloc[:,0]\n",
    "        data[f'{i}'] = table.iloc[:,1]\n",
    "\n",
    "        # 1.2) Finding extra information, that the read_html doesn't pick up:\n",
    "        soup = BeautifulSoup(connector.browser.page_source, 'lxml')\n",
    "        name = soup.find('h1').text\n",
    "        data[f'Traits_{i}'][0] = 'Name' # Adding the name to first row of the df (This is always NaN, so doesn't delete vital data)\n",
    "        data[f'{i}'][0] = name\n",
    "\n",
    "        # 2) Creating a dictionary with all information, ensuring homogeneity in calls of keys between different WikiPages; the info is in different orders between wiki-sites.:\n",
    "        dic = {}\n",
    "        for j in range(0,len(data[f'Traits_{i}'])):\n",
    "            dic[str(data[f'Traits_{i}'][j])] = str(data[f'{i}'][j])\n",
    "\n",
    "        dic_list.append(dic)\n",
    "\n",
    "        # RETURN \n",
    "        connector.browser.get(url)\n",
    "        time.sleep(1)\n",
    "\n",
    "    return [data,dic_list]\n",
    "    #return dic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroScrape = WikiScraper(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  project connector_type             t   delta_t  \\\n0   0  Metroer       selenium  1.597668e+09 -0.907827   \n1   1  Metroer       selenium  1.597668e+09 -0.659327   \n2   2  Metroer       selenium  1.597669e+09 -0.652908   \n\n                                                 url  \\\n0  https://da.wikipedia.org/wiki/Stationer_p%C3%A...   \n1  https://da.wikipedia.org/wiki/Stationer_p%C3%A...   \n2  https://da.wikipedia.org/wiki/Stationer_p%C3%A...   \n\n                                        redirect_url  response_size  \\\n0  https://da.wikipedia.org/wiki/Stationer_p%C3%A...         126862   \n1  https://da.wikipedia.org/wiki/Stationer_p%C3%A...         126727   \n2  https://da.wikipedia.org/wiki/Stationer_p%C3%A...         131090   \n\n   response_code  success  error  \n0            NaN      NaN    NaN  \n1            NaN      NaN    NaN  \n2            NaN      NaN    NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>project</th>\n      <th>connector_type</th>\n      <th>t</th>\n      <th>delta_t</th>\n      <th>url</th>\n      <th>redirect_url</th>\n      <th>response_size</th>\n      <th>response_code</th>\n      <th>success</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>Metroer</td>\n      <td>selenium</td>\n      <td>1.597668e+09</td>\n      <td>-0.907827</td>\n      <td>https://da.wikipedia.org/wiki/Stationer_p%C3%A...</td>\n      <td>https://da.wikipedia.org/wiki/Stationer_p%C3%A...</td>\n      <td>126862</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>Metroer</td>\n      <td>selenium</td>\n      <td>1.597668e+09</td>\n      <td>-0.659327</td>\n      <td>https://da.wikipedia.org/wiki/Stationer_p%C3%A...</td>\n      <td>https://da.wikipedia.org/wiki/Stationer_p%C3%A...</td>\n      <td>126727</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>Metroer</td>\n      <td>selenium</td>\n      <td>1.597669e+09</td>\n      <td>-0.652908</td>\n      <td>https://da.wikipedia.org/wiki/Stationer_p%C3%A...</td>\n      <td>https://da.wikipedia.org/wiki/Stationer_p%C3%A...</td>\n      <td>131090</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "MetroLog = pd.read_csv('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Logs/MetroLog.csv',sep=';').head(n=3)\n",
    "MetroLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Working with the data:\n",
    "\n",
    "Creating a DataFrame using the information from dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexlist = ['Name','Adresse','Jernbane','Åbningsdato']\n",
    "MetroList = pd.DataFrame(index=indexlist)\n",
    "\n",
    "for i in range(0,44):\n",
    "    specs = []\n",
    "    for j in indexlist:\n",
    "        try: \n",
    "            specs.append(MetroScrape[1][i][j]) # Appending the relevant Metro-information (j-key from scrape-dict)\n",
    "        except:\n",
    "            specs.append('NaN')\n",
    "    # Indexing column names:\n",
    "    MetroList[i] = specs\n",
    "MetroList = MetroList.transpose()\n",
    "MetroList.columns = ['Name', 'Address', 'Railroad', 'Opening Date'] # Changing names to english\n",
    "\n",
    "\n",
    "# Cleaning for '[1]' (from Wikipedia-references):\n",
    "MetroList['Address'] = [i.replace('[1]','') for i in MetroList['Address']]\n",
    "MetroList['Address'] = [i.replace('[2]','') for i in MetroList['Address']]\n",
    "MetroList['Railroad'] = [i.replace('[2]','') for i in MetroList['Railroad']]\n",
    "MetroList['Opening Date'] = [i.replace('[1]','') for i in MetroList['Opening Date']]\n",
    "\n",
    "# Cleaning NaN-values:\n",
    "MetroList = MetroList.drop(MetroList[\"Address\"].loc[MetroList[\"Address\"]=='NaN'].index)\n",
    "MetroList.reset_index(inplace=True)\n",
    "del MetroList['index']\n",
    "\n",
    "# Creating dummy-variable for Cityring:\n",
    "MetroList['Cityring'] = 0\n",
    "for i in range(0,len(MetroList)):\n",
    "    if 'Cityringen' in MetroList['Railroad'][i]:\n",
    "        MetroList['Cityring'][i] = 1\n",
    "\n",
    "# Simplyfying Opening Date-column to year for use in regression analysis later:\n",
    "for i in range(0,len(MetroList)):\n",
    "    try:\n",
    "        year = int(MetroList['Opening Date'][i][-4:])\n",
    "        if 0 < year < 2021:\n",
    "            MetroList['Opening Date'][i] = int(MetroList['Opening Date'][i][-4:])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Cleaning the rest by hand, example: '13. december 1986 (S-tog), 12. oktober 2003 (Metro)' is cleaned to 2003\n",
    "for i in [7,32]:\n",
    "    MetroList['Opening Date'][i] = 2003\n",
    "MetroList['Opening Date'][25] = 2002\n",
    "for i in [23,27,31,34]:\n",
    "    MetroList['Opening Date'][i] = 2019\n",
    "MetroList = MetroList.drop(22)\n",
    "MetroList.reset_index(inplace=True)\n",
    "del MetroList['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroList.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that the coordinates returned equals (39.78373,-100.445882) if there's a mistake (mostly, that the door and zip code are not separated by space) in the Address, I fix the very last issues manually in Excel in about a minute. This is no problem, as I am only working with 44 entries, and it would have been relatively difficult using RegEx, as the apartment numbers do not have the same number of digits and sometimes have letters in them. Too heterogenous. Speed before unneeded and superfluously complex code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to Excel:\n",
    "MetroList.to_excel('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Metro Adresses for Final Touches.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling edited version:\n",
    "MetroList = pd.read_excel('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Metro Adresses for Final Touches_DONE.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                         Name                            Address  \\\n0  Aksel Møllers Have Station  Godthåbsvej 31 2000 Frederiksberg   \n1       Amager Strand Station  Italiensvej 72A 2300 København S    \n2           Amagerbro Station  Amagerbro Torv 1 2300 København S   \n\n         Railroad  Opening Date  Cityring  \n0      Cityringen          2019         1  \n1  Østamagerbanen          2007         0  \n2   Ørestadsbanen          2002         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Address</th>\n      <th>Railroad</th>\n      <th>Opening Date</th>\n      <th>Cityring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Aksel Møllers Have Station</td>\n      <td>Godthåbsvej 31 2000 Frederiksberg</td>\n      <td>Cityringen</td>\n      <td>2019</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Amager Strand Station</td>\n      <td>Italiensvej 72A 2300 København S</td>\n      <td>Østamagerbanen</td>\n      <td>2007</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Amagerbro Station</td>\n      <td>Amagerbro Torv 1 2300 København S</td>\n      <td>Ørestadsbanen</td>\n      <td>2002</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "del MetroList['Unnamed: 0']\n",
    "MetroList.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) Finding Coordinates to each Metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroList['Coordinates'] = [Geocode_Google(i) for i in MetroList['Address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroList.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Metrolist With Coordinates.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroList = pickle.load(open('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Metrolist With Coordinates.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Finding the closest metro\n",
    "\n",
    "The code loops through each apartment in the Apartments dataframe. For each apartment, it sets an initial distance, after which it loops through each metro-station, calculate the distance to the given station, and substitute this for the default distance/metro if this distance is shorter. \n",
    "\n",
    "At last, when all metros have been upheld against each other for a given apartment, the key stats on the closest one are appended as a dictionary to the given apartment's row in the Apartments-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Closest_Metro(df,from_num,to_num):\n",
    "    # Creating a list of the closest metro to each apartment with the same index:\n",
    "    Closest_Metro = []\n",
    "    # Looping through each apartment:\n",
    "    for i in df['Coordinates'][from_num:to_num]:\n",
    "        # Initiating lowest distance and its metro\n",
    "        lowest_dist = 1000\n",
    "        # Looping through metros, finding all distances and substituting the shortest one\n",
    "        for j in range(0,len(MetroList['Coordinates'])):\n",
    "            dist = geopy.distance.distance(i, MetroList['Coordinates'][j]).km\n",
    "            if dist < lowest_dist:\n",
    "                name = MetroList['Name'][j]\n",
    "                lowest_dist = dist\n",
    "                add = MetroList['Address'][j]\n",
    "                railroad = MetroList['Railroad'][j]\n",
    "                opening_date = MetroList['Opening Date'][j]\n",
    "                cityring_indicator = MetroList['Cityring'][j]\n",
    "\n",
    "\n",
    "        Closest_Metro.append({'Name':name,'Distance':lowest_dist,'Address':add,'Railroad':railroad,'Opening Date':opening_date,'Cityring':cityring_indicator})\n",
    "    return Closest_Metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments['Closest Metro'] = Closest_Metro(Apartments,0,len(Apartments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments_API['Closest Metro'] = Closest_Metro(Apartments_API,0,len(Apartments_API))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments_API.to_pickle('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data API.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments = pickle.load(open('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data 4.pkl','rb'))\n",
    "Apartments_API = pickle.load(open('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Pickles/Apartment Data API.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartments[:3].to_excel('/Users/holger/Documents/Python/Harmsen_Repo/Metro-Study/Other data/illustration of df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            Address  \\\n0              Stengade 52B, 1. 1, 2200 København N   \n1                 Bryggerivej 10, 1. th, 2500 Valby   \n2              Solvænget 5, 3. tv, 2100 København Ø   \n3             Ved Volden 8, 5. tv, 1425 København K   \n4          Marstalsgade 38, 2. th, 2100 København Ø   \n...                                             ...   \n56944     Rådmandsgade 48A, 2. th, 2200 København N   \n56945  Tycho Brahes Allé 8, 5. tv, 2300 København S   \n56946        Theklavej 49, 2. 79, 2400 København NV   \n56947              Sundkaj 75, 3. th, 2150 Nordhavn   \n56948    Hammershøis Kaj 4, 2. th, 1402 København K   \n\n                        Address transformed   Area               Coordinates  \\\n0             Stengade 52B 2200 København N      N    (55.687083, 12.554688)   \n1                 Bryggerivej 10 2500 Valby  Valby    (55.660475, 12.518974)   \n2              Solvænget 5 2100 København Ø      Ø     (55.719198, 12.57804)   \n3             Ved Volden 8 1425 København K      K     (55.67202, 12.594053)   \n4          Marstalsgade 38 2100 København Ø      Ø    (55.703961, 12.589622)   \n...                                     ...    ...                       ...   \n56944     Rådmandsgade 48A 2200 København N      N    (55.700733, 12.552838)   \n56945  Tycho Brahes Allé 8 2300 København S      S  (55.6552045, 12.6111575)   \n56946        Theklavej 49 2400 København NV      V  (55.7059296, 12.5251929)   \n56947              Sundkaj 75 2150 Nordhavn    NaN  (55.7100897, 12.5977136)   \n56948    Hammershøis Kaj 4 1402 København K      K  (55.6709877, 12.5872917)   \n\n       Date_sold    Price  Price_mio  Price_sq_m_1000  Rooms  \\\n0     1994-02-11   300710   0.300710            5.896      1   \n1     1994-02-11   344101   0.344101            5.550      2   \n2     1994-02-11  1090300   1.090300            7.788      4   \n3     1994-02-13   415000   0.415000            6.694      2   \n4     1994-02-14   172000   0.172000            3.071      2   \n...          ...      ...        ...              ...    ...   \n56944 2020-07-16   816000   0.816000           14.836      2   \n56945 2020-07-16  1875000   1.875000           36.765      2   \n56946 2020-07-16  1550000   1.550000           38.750      1   \n56947 2020-07-16  3570000   3.570000           51.000      2   \n56948 2020-07-16  4250000   4.250000           57.432      2   \n\n                                           Closest Metro  \n0      {'Name': 'Forum Station', 'Distance': 0.609572...  \n1      {'Name': 'Enghave Plads Station', 'Distance': ...  \n2      {'Name': 'Poul Henningsens Plads Station', 'Di...  \n3      {'Name': 'Christianshavn Station', 'Distance':...  \n4      {'Name': 'Nordhavn Station', 'Distance': 0.122...  \n...                                                  ...  \n56944  {'Name': 'Vibenshus Runddel Station', 'Distanc...  \n56945  {'Name': 'Lergravsparken Station', 'Distance':...  \n56946  {'Name': 'Nørrebro Station', 'Distance': 0.980...  \n56947  {'Name': 'Orientkaj Station', 'Distance': 0.13...  \n56948  {'Name': 'Christianshavn Station', 'Distance':...  \n\n[56949 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Address</th>\n      <th>Address transformed</th>\n      <th>Area</th>\n      <th>Coordinates</th>\n      <th>Date_sold</th>\n      <th>Price</th>\n      <th>Price_mio</th>\n      <th>Price_sq_m_1000</th>\n      <th>Rooms</th>\n      <th>Closest Metro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Stengade 52B, 1. 1, 2200 København N</td>\n      <td>Stengade 52B 2200 København N</td>\n      <td>N</td>\n      <td>(55.687083, 12.554688)</td>\n      <td>1994-02-11</td>\n      <td>300710</td>\n      <td>0.300710</td>\n      <td>5.896</td>\n      <td>1</td>\n      <td>{'Name': 'Forum Station', 'Distance': 0.609572...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Bryggerivej 10, 1. th, 2500 Valby</td>\n      <td>Bryggerivej 10 2500 Valby</td>\n      <td>Valby</td>\n      <td>(55.660475, 12.518974)</td>\n      <td>1994-02-11</td>\n      <td>344101</td>\n      <td>0.344101</td>\n      <td>5.550</td>\n      <td>2</td>\n      <td>{'Name': 'Enghave Plads Station', 'Distance': ...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Solvænget 5, 3. tv, 2100 København Ø</td>\n      <td>Solvænget 5 2100 København Ø</td>\n      <td>Ø</td>\n      <td>(55.719198, 12.57804)</td>\n      <td>1994-02-11</td>\n      <td>1090300</td>\n      <td>1.090300</td>\n      <td>7.788</td>\n      <td>4</td>\n      <td>{'Name': 'Poul Henningsens Plads Station', 'Di...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Ved Volden 8, 5. tv, 1425 København K</td>\n      <td>Ved Volden 8 1425 København K</td>\n      <td>K</td>\n      <td>(55.67202, 12.594053)</td>\n      <td>1994-02-13</td>\n      <td>415000</td>\n      <td>0.415000</td>\n      <td>6.694</td>\n      <td>2</td>\n      <td>{'Name': 'Christianshavn Station', 'Distance':...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>Marstalsgade 38, 2. th, 2100 København Ø</td>\n      <td>Marstalsgade 38 2100 København Ø</td>\n      <td>Ø</td>\n      <td>(55.703961, 12.589622)</td>\n      <td>1994-02-14</td>\n      <td>172000</td>\n      <td>0.172000</td>\n      <td>3.071</td>\n      <td>2</td>\n      <td>{'Name': 'Nordhavn Station', 'Distance': 0.122...</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>56944</td>\n      <td>Rådmandsgade 48A, 2. th, 2200 København N</td>\n      <td>Rådmandsgade 48A 2200 København N</td>\n      <td>N</td>\n      <td>(55.700733, 12.552838)</td>\n      <td>2020-07-16</td>\n      <td>816000</td>\n      <td>0.816000</td>\n      <td>14.836</td>\n      <td>2</td>\n      <td>{'Name': 'Vibenshus Runddel Station', 'Distanc...</td>\n    </tr>\n    <tr>\n      <td>56945</td>\n      <td>Tycho Brahes Allé 8, 5. tv, 2300 København S</td>\n      <td>Tycho Brahes Allé 8 2300 København S</td>\n      <td>S</td>\n      <td>(55.6552045, 12.6111575)</td>\n      <td>2020-07-16</td>\n      <td>1875000</td>\n      <td>1.875000</td>\n      <td>36.765</td>\n      <td>2</td>\n      <td>{'Name': 'Lergravsparken Station', 'Distance':...</td>\n    </tr>\n    <tr>\n      <td>56946</td>\n      <td>Theklavej 49, 2. 79, 2400 København NV</td>\n      <td>Theklavej 49 2400 København NV</td>\n      <td>V</td>\n      <td>(55.7059296, 12.5251929)</td>\n      <td>2020-07-16</td>\n      <td>1550000</td>\n      <td>1.550000</td>\n      <td>38.750</td>\n      <td>1</td>\n      <td>{'Name': 'Nørrebro Station', 'Distance': 0.980...</td>\n    </tr>\n    <tr>\n      <td>56947</td>\n      <td>Sundkaj 75, 3. th, 2150 Nordhavn</td>\n      <td>Sundkaj 75 2150 Nordhavn</td>\n      <td>NaN</td>\n      <td>(55.7100897, 12.5977136)</td>\n      <td>2020-07-16</td>\n      <td>3570000</td>\n      <td>3.570000</td>\n      <td>51.000</td>\n      <td>2</td>\n      <td>{'Name': 'Orientkaj Station', 'Distance': 0.13...</td>\n    </tr>\n    <tr>\n      <td>56948</td>\n      <td>Hammershøis Kaj 4, 2. th, 1402 København K</td>\n      <td>Hammershøis Kaj 4 1402 København K</td>\n      <td>K</td>\n      <td>(55.6709877, 12.5872917)</td>\n      <td>2020-07-16</td>\n      <td>4250000</td>\n      <td>4.250000</td>\n      <td>57.432</td>\n      <td>2</td>\n      <td>{'Name': 'Christianshavn Station', 'Distance':...</td>\n    </tr>\n  </tbody>\n</table>\n<p>56949 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# The finished product ready for analysis:\n",
    "Apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}